{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gpstk\n",
    "from Toolkit import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', np.RankWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_PRN_list(ofile,nfile):\n",
    "    PRNs=[]\n",
    "    oheader,odata=gpstk.readRinex3Obs(ofile,strict=True) \n",
    "    nheader,ndata=gpstk.readRinex3Nav(nfile)\n",
    "    \n",
    "    bcestore = gpstk.GPSEphemerisStore() \n",
    "    \n",
    "    for ndato in ndata:\n",
    "        ephem = ndato.toGPSEphemeris()\n",
    "        bcestore.addEphemeris(ephem)\n",
    "    bcestore.SearchNear() \n",
    "    for observation in odata:\n",
    "        sats=[str(satID) for satID, datumList in observation.obs.iteritems() if str(satID).split()[0]==\"GPS\" ] \n",
    "        for sat in sats:\n",
    "            if sat not in PRNs:\n",
    "                PRNs.append(sat)\n",
    "    return PRNs\n",
    "\n",
    "def get_PRNsDATA(ofile,nfile):\n",
    "    f1,f2=gpstk.L1_FREQ_GPS,gpstk.L2_FREQ_GPS\n",
    "    alfa=1.0/((f1**2/f2**2)-1) \n",
    "    h=400.0e3 #the height of the ionospheric layer, which is assumed to be 400 km in this paper\n",
    "    Re=6371.0e3 #Earth Radius\n",
    "    gamma=gpstk.GAMMA_GPS\n",
    "    PRNs=get_PRN_list(ofile,nfile)\n",
    "    info_recv={}\n",
    "    for PRN in PRNs:\n",
    "        t,Icode,Iphase,__,ELEV,IPPS,L1,L2,C1,C2,Tgd=getdata(nfile,ofile,PRN)\n",
    "        obs=get_arcs(t,Icode,Iphase,ELEV,IPPS,L1,L2,C1,C2) #gets arcs with Phase, Code, and adjusted times observations\n",
    "        LevelArc={} #key:arc\n",
    "        Time={}\n",
    "        Zen={}\n",
    "        for arc in range(len(obs)):\n",
    "            time=obs[arc][0]\n",
    "            Phase=obs[arc][1]\n",
    "            Code=obs[arc][2]\n",
    "            Elevation=obs[arc][3]\n",
    "\n",
    "            #Phase on frequency L1,L2 station1\n",
    "            PhaseL1=obs[arc][4]\n",
    "            PhaseL2=obs[arc][5]\n",
    "            CodeL1=obs[arc][6]\n",
    "            CodeL2=obs[arc][7]\n",
    "            #Detect data jumps on L=L1-L2\n",
    "            jumps=datajump(Phase,2.5)\n",
    "\n",
    "            #Divide in Sub-arcs using jumps\n",
    "            miniarcs=sub_arcs(Phase,jumps)\n",
    "\n",
    "            #Remove short arcs \n",
    "            toerase=[]\n",
    "            for subarc in range(len(miniarcs)):\n",
    "                if miniarcs[subarc].size<10:\n",
    "                    toerase.append(subarc)\n",
    "            miniarcs=np.delete(miniarcs,tuple(toerase))\n",
    "        \n",
    "            #Polinomial fit and Outlier Detection\n",
    "            ##On each subarc check for slips and delete.\n",
    "            pslips=[] #slips with polinomyal fit\n",
    "            oslips=[] #slips oulier factor\n",
    "\n",
    "            for i in miniarcs:\n",
    "                __,pslip=poly_fit(Phase[i],time[i])\n",
    "                pslips.append(pslip)\n",
    "                __,oslip=outlier_detect(Phase[i],time[i]*3600)\n",
    "                oslips.append(oslip)\n",
    "\n",
    "\n",
    "            ##Using polinompyal fit and outlier factor methods we confirm slips\n",
    "            confirmed=[] #a list of lists with the confirmed outliers on each subarc\n",
    "\n",
    "            for i in miniarcs:\n",
    "                outliers=confirmed_slip(time[i],Phase[i])\n",
    "                confirmed.append(outliers)\n",
    "            \n",
    "            #############\n",
    "\n",
    "            #Remove slips from both stations\n",
    "            for i in range(len(confirmed)):\n",
    "                if len(confirmed[i])!=0:\n",
    "                    miniarcs[i]=np.delete(miniarcs[i],oslips[i])\n",
    "\n",
    "\n",
    "            #Hatch Filter for code smoothing on each frequency before leveling\n",
    "            #in every subarc\n",
    "            newC1,newC2=CodeL1,CodeL2\n",
    "\n",
    "            for i in miniarcs:\n",
    "                newC1[i]=Smooth_code(CodeL1[i],PhaseL1[i]) #Codigo suavisado en L1 y L2\n",
    "                newC2[i]=Smooth_code(CodeL2[i],PhaseL2[i])\n",
    "\n",
    "\n",
    "            newC=(newC2-newC1)*alfa\n",
    "\n",
    "            #Leveling Phase\n",
    "            PhaseArc=[] #lists with subarcs leveled\n",
    "            C=[]\n",
    "            OldC=[]\n",
    "            PhaseL1,PhaseL2=[],[]\n",
    "            zenith=[]\n",
    "\n",
    "            for i in miniarcs:\n",
    "                Lfactor,new_IPHASE_arc=levelphase(newC[i],Phase[i],Elevation[i])\n",
    "                PhaseArc.append(new_IPHASE_arc)  \n",
    "                C.append(newC[i])\n",
    "                OldC.append(Code[i])\n",
    "                zenith.append(np.arcsin((Re*np.cos(Elevation[i])/(Re+h))))\n",
    "                \n",
    "\n",
    "\n",
    "            #Here all subarcs are merged into one single corrected continuous arc.\n",
    "            new_IPHASE_arc=np.hstack(PhaseArc)\n",
    "            C=np.hstack(C)\n",
    "            OldC=np.hstack(OldC)\n",
    "            zenith=np.hstack(zenith)\n",
    "            \n",
    "            ntimes=np.array([])\n",
    "\n",
    "            for i in miniarcs:\n",
    "                ntimes=np.append(ntimes,time[i])\n",
    "                \n",
    "            LevelArc[arc]=new_IPHASE_arc\n",
    "            Time[arc]=ntimes\n",
    "            Zen[arc]=zenith\n",
    "        #LevelArc=np.hstack(LevelArc) #esto juntaría dos arcos separados! D:\n",
    "        #Time=np.hstack(Time)\n",
    "        #Zen=np.hstack(Zen)\n",
    "        info_recv[PRN]=[Time,LevelArc,Tgd,Zen] #diccionario de diccs\n",
    "    return info_recv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Receiver IFB</h1>\n",
    "\n",
    "\n",
    "En este método se asume que la variación del vTEC (vertical ionospheric delays) de todos los satélites visibles en un instante es mínima cuando el ruido IFB(presente en el rinex y/o ionex) del satélite se remueve correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos Despejar el IFB de receptor con la ecuación\n",
    "\n",
    "$$vTEC=(TEC_{sl}-b_{s}-b_{r})Cos(\\chi)$$\n",
    "**Conocemos:**<br><br>\n",
    "$TEC_{sl}$: Tec slant<br>\n",
    "$\\chi$: Zenith, $b_{s}$: Bias Satellite, incluido en rinex y/o ionex<br> \n",
    "<br><br>**Incognita:**<br><br>\n",
    "$b_{r}$: Bias receptor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Receptor_IFB_Bias.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\sigma_{t,u}$ es la sumatoria de todas las desviaciones en el día con un bías aleatorio. \n",
    "\n",
    "\n",
    "$\\sigma_{u}(n)$ es la desviación de $VTEC$ en un instante $n$. Esto es sin errores de ambiguedad en la medida del delay en carrier.\n",
    "\n",
    "\n",
    "$VTEC$ Vertical Total Electron Content medido por un solo satélite en tiempo $n$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getIFB_Rec(ofile,nfile): #en cada epoca satelites que ve, L1,L2,P1,P2,Elevacion de cada satelite,IFB satelites (del rinex toca)\n",
    "    sat_data=get_PRNsDATA(ofile,nfile)\n",
    "    array={}\n",
    "    for prn in sat_data.keys():\n",
    "        data=sat_data[prn]\n",
    "        arcos=sat_data[prn][0].keys()\n",
    "        for arc in arcos: \n",
    "            times=data[0][arc]\n",
    "            TEC_sl=data[1][arc]\n",
    "            Tgd=data[2]\n",
    "            zenith=data[3][arc]\n",
    "            for t in range(len(times)):\n",
    "                if times[t] not in array:\n",
    "                    array[times[t]]=[[prn],[TEC_sl[t]],Tgd,[zenith[t]] ] #[PRN], [TEC_SLANT(PHASELEVEL)],Tgd,[Zenith]\n",
    "                \n",
    "                else:\n",
    "                    array[times[t]][0].append(prn) #PRN\n",
    "                    array[times[t]][1].append(TEC_sl[t]) #TEC slant\n",
    "                    array[times[t]][3].append(zenith[t]) #zenith\n",
    "    ############################################################################\n",
    "    bias=np.arange(-30,30,0.1)*1e-9#600\n",
    "    c=3e8\n",
    "    vec_sum_desv=[] #vector with all sumdesv for every bias\n",
    "    for bi in bias: #Cada bias candidato\n",
    "        sumdesv_u=0 #sum of all standar desv  of that day with bias \"bi\"\n",
    "        for n in array: \n",
    "            Mt=len(array[n][0]) #number of satellites observed at time n\n",
    "            #print Mt, \"Satelites en tiempo \",n\n",
    "            TEC=[]\n",
    "            for m in range(Mt):\n",
    "                TECsl=array[n][1][m]\n",
    "                tgd=array[n][2]\n",
    "                zenith=array[n][3][m]\n",
    "                vTEC=(TECsl-tgd-(bi*c))*np.cos(zenith)\n",
    "                TEC.append(vTEC)\n",
    "            desv_u=np.std(TEC) #sigma_u en tiempo n\n",
    "            sumdesv_u=sumdesv_u+desv_u\n",
    "        vec_sum_desv.append(sumdesv_u)\n",
    "    best_bias=bias[np.argmin(vec_sum_desv)]\n",
    "    return array,best_bias    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ofile,nfile=\"conus_articulo/garf324.03.o\",\"conus_articulo/garf324.03.n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print \"Satellites in t=  0.0 seconds: \",array[0.0][0]\n",
    "#print \"Satellites in t=480.0 seconds: \",array[5400.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poly:  4 Outlier factor:  4\n",
      "Poly:  0 Outlier factor:  0\n",
      "Poly:  5 Outlier factor:  5\n",
      "Poly:  11 Outlier factor:  11\n",
      "Poly:  31 Outlier factor:  31\n",
      "Poly:  45 Outlier factor:  45\n"
     ]
    }
   ],
   "source": [
    "Stations=[\n",
    "[\"conus_articulo/leba324.03.n\",\"conus_articulo/leba324.03.o\"],\n",
    "[\"conus_articulo/colb324.03.n\",\"conus_articulo/colb324.03.o\"],\n",
    "[\"conus_articulo/freo324.03.n\",\"conus_articulo/freo324.03.o\"],\n",
    "[\"conus_articulo/mtvr324.03.n\",\"conus_articulo/mtvr324.03.o\"],\n",
    "[\"conus_articulo/erla324.03.n\",\"conus_articulo/erla324.03.o\"],\n",
    "[\"conus_articulo/woos324.03.n\",\"conus_articulo/woos324.03.o\"],\n",
    "[\"conus_articulo/lsbn324.03.n\",\"conus_articulo/lsbn324.03.o\"],\n",
    "[\"conus_articulo/grtn324.03.n\",\"conus_articulo/grtn324.03.o\"],\n",
    "[\"conus_articulo/zob1324.03.n\",\"conus_articulo/zob1324.03.o\"]]\n",
    "\n",
    "bias=[]\n",
    "\n",
    "for station in Stations:\n",
    "    nfile=station[0]\n",
    "    ofile=station[1]\n",
    "    name=ofile.split('/')[1][:4]\n",
    "    __,bi=getIFB_Rec(ofile,nfile)\n",
    "    bias.append((bi,name))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-1.0499999999999723e-08, 'leba'),\n",
       " (-1.0699999999999727e-08, 'colb'),\n",
       " (-1.7599999999999823e-08, 'freo'),\n",
       " (-1.5199999999999792e-08, 'mtvr'),\n",
       " (2.990000000000085e-08, 'erla'),\n",
       " (-1.159999999999974e-08, 'woos'),\n",
       " (-2.3899999999999916e-08, 'lsbn'),\n",
       " (-2.5599999999999938e-08, 'grtn'),\n",
       " (-2.0999999999996036e-09, 'zob1')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
